<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Documentation - Universal Automation Wiki</title>
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="stylesheet" href="/assets/css/components.css">
    <link rel="stylesheet" href="/assets/css/category.css"> <!-- For nav cards -->
    <link rel="stylesheet" href="/assets/css/responsive.css">
    <link rel="stylesheet" href="/assets/css/documentation.css"> <!-- Added documentation styles -->
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        /* Placeholder styles to prevent layout shift */
        #header-placeholder { min-height: 70px; }
        #footer-placeholder { min-height: 250px; }
    </style>
</head>
<body>
    <div id="header-placeholder"></div>

    <div class="docs-layout">
        <div id="sidebar-placeholder"></div>

        <main>
            <section class="hero">
                <div class="container">
                    <h1>Automation ROI Analysis</h1>
                    <p class="hero-subtitle">This script utilizes a Large Language Model (LLM) to generate a structured Return on Investment (ROI) analysis for implementing automation technologies related to a specific topic. It processes an input JSON file containing the topic and optional model parameters, interacts with the LLM, parses the response, and saves the structured analysis along with metadata to an output JSON file.</p>
                </div>
            </section>
            <div class="spacer"></div>
            <section class="content-section">
                <div class="spacer"></div>

                <h1>Automation ROI Analysis</h1>
<p>This script utilizes a Large Language Model (LLM) to generate a structured Return on Investment (ROI) analysis for implementing automation technologies related to a specific topic. It processes an input JSON file containing the topic and optional model parameters, interacts with the LLM, parses the response, and saves the structured analysis along with metadata to an output JSON file.</p>
<h2>Purpose</h2>
<p>The primary goal of <code>return-analysis.py</code> is to automate the generation of ROI assessments for automation projects. It prompts an LLM to analyze the potential returns across small, medium, and large production scales, providing insights into investment, savings, benefits, barriers, and recommendations in a standardized JSON format.</p>
<h2>Usage</h2>
<p>The script is executed from the command line:</p>
<div class="codehilite"><pre><span></span><code>python<span class="w"> </span><span class="k">return</span>-analysis.py<span class="w"> </span>&lt;input_json&gt;<span class="w"> </span><span class="o">[</span>output_json<span class="o">]</span><span class="w"> </span><span class="o">[</span>-saveInputs<span class="o">]</span><span class="w"> </span><span class="o">[</span>-uuid<span class="o">=</span><span class="s2">&quot;UUID&quot;</span><span class="o">]</span><span class="w"> </span><span class="o">[</span>-flow_uuid<span class="o">=</span><span class="s2">&quot;FLOW-UUID&quot;</span><span class="o">]</span>
</code></pre></div>

<ul>
<li><code>&lt;input_json&gt;</code>: (Required) Path to the input JSON file containing the analysis parameters.</li>
<li><code>[output_json]</code>: (Optional) Path where the output JSON file should be saved. If omitted, a default path is generated based on the script name and a UUID.</li>
<li><code>-saveInputs</code>: (Optional) Flag to save the system and user prompts sent to the LLM into the <code>flow/&lt;flowUUID&gt;/inputs/</code> directory.</li>
<li><code>-uuid="UUID"</code>: (Optional) Specify a custom UUID for the output file metadata.</li>
<li><code>-flow_uuid="FLOW-UUID"</code>: (Optional) Specify the UUID for the flow, used for saving inputs if <code>-saveInputs</code> is active.</li>
</ul>
<h2>Input Files</h2>
<p>The script expects an input JSON file with the following structure:</p>
<div class="codehilite"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;topic&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;The specific area or process for automation ROI analysis&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gemma3&quot;</span><span class="p">,</span><span class="w"> </span><span class="c1">// Optional: Specify the LLM model (defaults if not provided)</span>
<span class="w">  </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{}</span><span class="w"> </span><span class="c1">// Optional: Additional parameters for the LLM call</span>
<span class="p">}</span>
</code></pre></div>

<ul>
<li><code>topic</code>: A string describing the subject of the ROI analysis.</li>
<li><code>model</code>: (Optional) The identifier for the LLM to use (e.g., "gemma3").</li>
<li><code>parameters</code>: (Optional) A JSON object containing any specific parameters for the LLM interaction (handled by <code>utils.chat_with_llm</code>).</li>
</ul>
<h2>Key Functions</h2>
<ul>
<li><strong><code>sanitize_json_string(json_str)</code></strong>: Removes invalid control characters (ASCII 0-31, excluding tab, newline, carriage return) from a string to prevent JSON parsing errors.</li>
<li><strong><code>extract_json_from_response(response)</code></strong>: Attempts to extract and parse a valid JSON object from the LLM's raw response string. It tries:<ol>
<li>Direct parsing of the (sanitized) response.</li>
<li>Extracting content within JSON code fences (e.g., <code>json ...</code>).</li>
<li>Extracting content within the first opening <code>{</code> and last closing <code>}</code>.
Returns the parsed JSON object or <code>None</code> if parsing fails.</li>
</ol>
</li>
<li><strong><code>generate_roi_analysis(input_data, save_inputs=False)</code></strong>: Orchestrates the ROI analysis generation. It extracts the <code>topic</code>, <code>model</code>, and <code>parameters</code> from the input, constructs the system and user prompts, optionally saves the prompts using <code>utils.saveToFile</code>, calls <code>utils.chat_with_llm</code> to get the LLM response, and uses <code>extract_json_from_response</code> to parse the result.</li>
<li><strong><code>main()</code></strong>: The main execution function. It handles command-line arguments using <code>utils.handle_command_args</code>, loads the input JSON using <code>utils.load_json</code>, calls <code>generate_roi_analysis</code>, determines the output path using <code>utils.get_output_filepath</code>, creates metadata using <code>utils.create_output_metadata</code>, combines metadata with the analysis results, and saves the final output using <code>utils.save_output</code>. It exits if <code>generate_roi_analysis</code> fails to return valid JSON data.</li>
<li><strong><code>utils</code> Functions</strong>: Relies on helper functions from <code>utils.py</code> for common tasks like loading JSON (<code>load_json</code>), saving output (<code>save_output</code>), interacting with the LLM (<code>chat_with_llm</code>), creating metadata (<code>create_output_metadata</code>), determining file paths (<code>get_output_filepath</code>), handling arguments (<code>handle_command_args</code>), and saving intermediate files (<code>saveToFile</code>).</li>
</ul>
<h2>LLM Interaction</h2>
<p>The script crafts specific prompts for the LLM:</p>
<ul>
<li><strong>System Prompt</strong>: Instructs the LLM to act as an AI assistant specialized in ROI analysis for automation, focusing on small, medium, and large production scales.</li>
<li><strong>User Prompt</strong>: Provides the specific <code>topic</code> and explicitly requests the output in a JSON format with a defined structure:<ul>
<li><code>roi_analysis</code>: An object containing keys <code>small_scale</code>, <code>medium_scale</code>, <code>large_scale</code>. Each scale object must include:<ul>
<li><code>timeframe</code>: Typical ROI timeframe (string).</li>
<li><code>initial_investment</code>: Estimated investment range (string).</li>
<li><code>annual_savings</code>: Estimated annual savings (string).</li>
<li><code>key_considerations</code>: Array of factors affecting ROI at that scale.</li>
</ul>
</li>
<li><code>key_benefits</code>: An array of significant benefits across all scales.</li>
<li><code>barriers</code>: An array of common challenges to achieving ROI.</li>
<li><code>recommendation</code>: A brief suggestion on which scale benefits most.
The prompt strongly emphasizes returning <em>only</em> the valid JSON object without any surrounding text or formatting.</li>
</ul>
</li>
<li>The interaction is performed using the <code>utils.chat_with_llm</code> function.</li>
</ul>
<h2>JSON Handling</h2>
<p>Robust JSON handling is crucial as LLM output can be inconsistent.
*   <code>sanitize_json_string</code> preprocesses the LLM response to remove characters that would cause <code>json.loads</code> to fail.
*   <code>extract_json_from_response</code> implements a multi-stage parsing strategy:
    1.  It first tries to parse the entire sanitized response directly.
    2.  If that fails, it looks for JSON content enclosed in <code>json ...</code> or <code>...</code> code fences.
    3.  If still unsuccessful, it attempts to parse the content between the first <code>{</code> and the last <code>}</code> in the response.
This approach increases the likelihood of successfully extracting the desired JSON data even if the LLM includes extraneous text or formatting.</p>
<h2>Output</h2>
<p>The script generates a JSON file containing:</p>
<ol>
<li><strong>Process Metadata</strong>: Information about the script execution, including the task name ("Automation ROI Analysis"), start time, and a unique UUID, generated by <code>utils.create_output_metadata</code>.</li>
<li><strong>ROI Analysis</strong>: The <code>roi_analysis</code> key holds the structured JSON object parsed from the LLM response, containing the detailed analysis across different scales, benefits, barriers, and the recommendation.</li>
</ol>
<p>Example Output Structure:</p>
<div class="codehilite"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;process_metadata&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;task_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Automation ROI Analysis&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;start_time&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;YYYY-MM-DDTHH:MM:SS.ffffff&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;end_time&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;YYYY-MM-DDTHH:MM:SS.ffffff&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;duration_seconds&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">15.234</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;uuid&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;generated-or-specified-uuid&quot;</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;roi_analysis&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;roi_analysis&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;small_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;timeframe&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;...&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;initial_investment&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;...&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;annual_savings&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;...&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;key_considerations&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;...&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;...&quot;</span><span class="p">]</span>
<span class="w">      </span><span class="p">},</span>
<span class="w">      </span><span class="nt">&quot;medium_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="cm">/* ... */</span><span class="w"> </span><span class="p">},</span>
<span class="w">      </span><span class="nt">&quot;large_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="cm">/* ... */</span><span class="w"> </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;key_benefits&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;...&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;...&quot;</span><span class="p">],</span>
<span class="w">    </span><span class="nt">&quot;barriers&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;...&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;...&quot;</span><span class="p">],</span>
<span class="w">    </span><span class="nt">&quot;recommendation&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;...&quot;</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p>If the script cannot extract or parse valid JSON from the LLM response after trying all methods in <code>extract_json_from_response</code>, it prints an error message and exits with a non-zero status code.</p>
<style>
/* Code highlighting styles */
.codehilite .hll { background-color: #ffffcc }
.codehilite { background: #f8f8f8; padding: 0.5em; border-radius: 4px; overflow: auto; }
.codehilite .c { color: #3D7B7B; font-style: italic } /* Comment */
.codehilite .err { border: 1px solid #FF0000 } /* Error */
.codehilite .k { color: #008000; font-weight: bold } /* Keyword */
.codehilite .o { color: #666666 } /* Operator */
.codehilite .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */
.codehilite .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */
.codehilite .cp { color: #9C6500 } /* Comment.Preproc */
.codehilite .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */
.codehilite .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */
.codehilite .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */
.codehilite .gd { color: #A00000 } /* Generic.Deleted */
.codehilite .ge { font-style: italic } /* Generic.Emph */
.codehilite .gr { color: #E40000 } /* Generic.Error */
.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.codehilite .gi { color: #008400 } /* Generic.Inserted */
.codehilite .go { color: #717171 } /* Generic.Output */
.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.codehilite .gs { font-weight: bold } /* Generic.Strong */
.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.codehilite .gt { color: #0044DD } /* Generic.Traceback */
.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.codehilite .kp { color: #008000 } /* Keyword.Pseudo */
.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.codehilite .kt { color: #B00040 } /* Keyword.Type */
.codehilite .m { color: #666666 } /* Literal.Number */
.codehilite .s { color: #BA2121 } /* Literal.String */
.codehilite .na { color: #687822 } /* Name.Attribute */
.codehilite .nb { color: #008000 } /* Name.Builtin */
.codehilite .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.codehilite .no { color: #880000 } /* Name.Constant */
.codehilite .nd { color: #AA22FF } /* Name.Decorator */
.codehilite .ni { color: #717171; font-weight: bold } /* Name.Entity */
.codehilite .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */
.codehilite .nf { color: #0000FF } /* Name.Function */
.codehilite .nl { color: #767600 } /* Name.Label */
.codehilite .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */
.codehilite .nv { color: #19177C } /* Name.Variable */
.codehilite .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.codehilite .w { color: #bbbbbb } /* Text.Whitespace */
.codehilite .mb { color: #666666 } /* Literal.Number.Bin */
.codehilite .mf { color: #666666 } /* Literal.Number.Float */
.codehilite .mh { color: #666666 } /* Literal.Number.Hex */
.codehilite .mi { color: #666666 } /* Literal.Number.Integer */
.codehilite .mo { color: #666666 } /* Literal.Number.Oct */
.codehilite .sa { color: #BA2121 } /* Literal.String.Affix */
.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */
.codehilite .sc { color: #BA2121 } /* Literal.String.Char */
.codehilite .dl { color: #BA2121 } /* Literal.String.Delimiter */
.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */
.codehilite .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */
.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */
.codehilite .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */
.codehilite .sx { color: #008000 } /* Literal.String.Other */
.codehilite .sr { color: #A45A77 } /* Literal.String.Regex */
.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */
.codehilite .ss { color: #19177C } /* Literal.String.Symbol */
.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */
.codehilite .fm { color: #0000FF } /* Name.Function.Magic */
.codehilite .vc { color: #19177C } /* Name.Variable.Class */
.codehilite .vg { color: #19177C } /* Name.Variable.Global */
.codehilite .vi { color: #19177C } /* Name.Variable.Instance */
.codehilite .vm { color: #19177C } /* Name.Variable.Magic */
.codehilite .il { color: #666666 } /* Literal.Number.Integer.Long */

/* Additional styling for specific code elements */
.codehilite pre { margin: 0; padding: 10px; white-space: pre; }
.codehilite code { font-family: 'Consolas', 'Monaco', 'Andale Mono', 'Ubuntu Mono', monospace; }
</style>

            </section>

        </main>
    </div>

    <div id="footer-placeholder"></div>

    <script src="/assets/js/components.js"></script>
<script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true });
    </script>
    <script src="/assets/js/main.js"></script>
    <script src="/assets/js/documentation.js"></script>
    <script>renderDocumentationSidebar('#sidebar-placeholder');</script>
</body>
</html>