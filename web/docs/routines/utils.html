<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Documentation - Universal Automation Wiki</title>
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="stylesheet" href="/assets/css/components.css">
    <link rel="stylesheet" href="/assets/css/category.css"> <!-- For nav cards -->
    <link rel="stylesheet" href="/assets/css/responsive.css">
    <link rel="stylesheet" href="/assets/css/documentation.css"> <!-- Added documentation styles -->
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=IBM+Plex+Sans:wght@400;500;600;700&family=Geologica:wght@400;500;600;700;800;900&display=swap" rel="stylesheet">
    <style>
        /* Placeholder styles to prevent layout shift */
        #header-placeholder { min-height: 70px; }
        #footer-placeholder { min-height: 250px; }
    </style>
</head>
<body>
    <div id="header-placeholder"></div>

    <div class="docs-layout">
        <div id="sidebar-placeholder"></div>

        <main>
            <section class="hero">
                <div class="container">
                    <h1>Utility Functions</h1>
                    <p class="hero-subtitle">This script provides a collection of common helper functions used by various automation and processing scripts within the project. It includes functions for file I/O, JSON handling, interacting with Large Language Models (LLMs) via Ollama, processing LLM responses, managing command-line arguments, and generating metadata.</p>
                </div>
            </section>
            <div class="spacer"></div>
            <section class="content-section">
                <div class="spacer"></div>

                <h1>Utility Functions</h1>
<p>This script provides a collection of common helper functions used by various automation and processing scripts within the project. It includes functions for file I/O, JSON handling, interacting with Large Language Models (LLMs) via Ollama, processing LLM responses, managing command-line arguments, and generating metadata.</p>
<h2>load_json</h2>
<p>Loads data from a specified JSON file.</p>
<ul>
<li><strong>Purpose:</strong> Reads a JSON file from the given <code>filepath</code> and returns the parsed Python object (typically a dictionary or list).</li>
<li><strong>Usage:</strong> <code>data = load_json("path/to/input.json")</code></li>
</ul>
<h2>save_output</h2>
<p>Saves Python data structures to a JSON file.</p>
<ul>
<li><strong>Purpose:</strong> Writes the provided <code>output_data</code> to the specified <code>output_filepath</code> in JSON format with indentation. It automatically creates the necessary output directory if it doesn't exist.</li>
<li><strong>Usage:</strong> <code>save_output(my_data, "output/results.json")</code></li>
</ul>
<h2>parse_embedded_json</h2>
<p>Recursively parses JSON strings embedded within node structures.</p>
<ul>
<li><strong>Purpose:</strong> Checks if the <code>step</code> field of a dictionary (node) contains a string that looks like a JSON array or object. If it does, it parses the JSON and replaces the node's <code>children</code> field with the parsed content. This is useful for handling nested structures generated by LLMs where steps might contain further sub-steps defined as JSON. If the node doesn't have a <code>title</code>, the original <code>step</code> string is used as the title after parsing.</li>
<li><strong>Usage:</strong> <code>processed_node = parse_embedded_json(node_with_potential_json_step)</code></li>
</ul>
<h2>chat_with_llm</h2>
<p>Interacts with a specified Ollama LLM.</p>
<ul>
<li><strong>Purpose:</strong> Provides a generic interface to send a system message and a user message to an LLM (specified by <code>model</code>) using the <code>ollama</code> library. It accepts optional <code>parameters</code> for the Ollama API call.</li>
<li><strong>Returns:</strong> The content of the LLM's response as a cleaned string.</li>
<li><strong>Usage:</strong> <code>response = chat_with_llm("gemma3", "System prompt", "User query", {"temperature": 0.7})</code></li>
</ul>
<h2>clean_llm_json_response</h2>
<p>Cleans up potential JSON responses from an LLM.</p>
<ul>
<li><strong>Purpose:</strong> Attempts to extract a valid JSON object or array from a raw LLM response string. It removes common artifacts like Markdown code fences (<code>```json</code>, <code>```</code>).</li>
<li><strong>Returns:</strong> The extracted JSON string if found, otherwise the cleaned-up text.</li>
<li><strong>Usage:</strong> <code>json_string = clean_llm_json_response(raw_llm_output)</code></li>
</ul>
<h2>parse_llm_json_response</h2>
<p>Parses JSON from an LLM response with fallback handling.</p>
<ul>
<li><strong>Purpose:</strong> Takes raw LLM response text, cleans it using <code>clean_llm_json_response</code>, and attempts to parse it as JSON.</li>
<li><strong>Fallback:</strong> If JSON parsing fails, it splits the cleaned text by lines and returns a list of dictionaries.<ul>
<li>If <code>include_children</code> is <code>True</code>, each dictionary will have the structure <code>{"step": "line content", "children": []}</code>.</li>
<li>If <code>include_children</code> is <code>False</code> (default), each dictionary will have the structure <code>{"step": "line content"}</code>.</li>
</ul>
</li>
<li><strong>Usage:</strong> <code>parsed_data = parse_llm_json_response(raw_llm_output, include_children=True)</code></li>
</ul>
<h2>create_output_metadata</h2>
<p>Generates standard metadata for output files.</p>
<ul>
<li><strong>Purpose:</strong> Creates a dictionary containing common metadata associated with a task's output, including a UUID (<code>output_uuid</code>), creation timestamp, the <code>task_name</code>, and the time taken (calculated from the <code>start_time</code>).</li>
<li><strong>Usage:</strong> <code>metadata = create_output_metadata("Data Processing", start_timestamp, generated_uuid)</code></li>
</ul>
<h2>get_output_filepath</h2>
<p>Determines the final path for an output file.</p>
<ul>
<li><strong>Purpose:</strong> Returns the appropriate file path for saving output. If <code>specified_path</code> is provided, it's used directly. Otherwise, it constructs a path within the <code>output/{output_dir}</code> directory using a provided or newly generated <code>output_uuid</code>. It ensures the output directory exists.</li>
<li><strong>Returns:</strong> A tuple containing the determined filepath and the UUID used.</li>
<li><strong>Usage:</strong> <code>filepath, uuid = get_output_filepath("processed_data", output_uuid=my_uuid)</code> or <code>filepath, uuid = get_output_filepath("results", specified_path="custom/output/final.json")</code></li>
</ul>
<h2>handle_command_args</h2>
<p>Parses and validates common command-line arguments.</p>
<ul>
<li><strong>Purpose:</strong> Processes <code>sys.argv</code> to extract input/output file paths and common flags like <code>-saveInputs</code> (for debugging prompts), <code>-uuid=&lt;value&gt;</code> (to specify an output UUID), and <code>-flow_uuid=&lt;value&gt;</code>. It validates the number of positional arguments against <code>min_args</code> and <code>max_args</code>.</li>
<li><strong>Returns:</strong> A tuple containing <code>input_filepath</code>, <code>output_filepath</code>, <code>save_inputs</code> (boolean), <code>custom_uuid</code>, and <code>flow_uuid</code>.</li>
<li><strong>Usage:</strong> <code>input_path, output_path, save_flag, uuid, flow_id = handle_command_args("Usage: script.py &lt;input&gt; [output]", min_args=1, max_args=2)</code></li>
</ul>
<h2>saveToFile</h2>
<p>Saves LLM prompts to a file for debugging.</p>
<ul>
<li><strong>Purpose:</strong> Used specifically when the <code>-saveInputs</code> flag is detected by <code>handle_command_args</code>. It saves the <code>system_message</code> and <code>user_message</code> sent to the LLM, along with a timestamp, into a specified JSON <code>filepath</code>.</li>
<li><strong>Usage:</strong> Typically called internally after parsing arguments if <code>save_inputs</code> is true. <code>saveToFile(system_prompt, user_prompt, "debug/prompts/prompt_abc.json")</code></li>
</ul>
<h2>translate_to_basic_english</h2>
<p>Translates text into simple Basic English using an LLM.</p>
<ul>
<li><strong>Purpose:</strong> Takes input <code>text</code> and uses the <code>chat_with_llm</code> function to request a translation into very short, simple Basic English (using the 850-word list). The output is cleaned and truncated to be suitable for use as a file or folder name.</li>
<li><strong>Usage:</strong> <code>folder_name_part = translate_to_basic_english("Complex technical description")</code></li>
</ul>
<style>
/* Code highlighting styles */
.codehilite .hll { background-color: #ffffcc }
.codehilite { background: #f8f8f8; padding: 0.5em; border-radius: 4px; overflow: auto; }
.codehilite .c { color: #3D7B7B; font-style: italic } /* Comment */
.codehilite .err { border: 1px solid #FF0000 } /* Error */
.codehilite .k { color: #008000; font-weight: bold } /* Keyword */
.codehilite .o { color: #666666 } /* Operator */
.codehilite .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */
.codehilite .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */
.codehilite .cp { color: #9C6500 } /* Comment.Preproc */
.codehilite .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */
.codehilite .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */
.codehilite .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */
.codehilite .gd { color: #A00000 } /* Generic.Deleted */
.codehilite .ge { font-style: italic } /* Generic.Emph */
.codehilite .gr { color: #E40000 } /* Generic.Error */
.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.codehilite .gi { color: #008400 } /* Generic.Inserted */
.codehilite .go { color: #717171 } /* Generic.Output */
.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.codehilite .gs { font-weight: bold } /* Generic.Strong */
.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.codehilite .gt { color: #0044DD } /* Generic.Traceback */
.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.codehilite .kp { color: #008000 } /* Keyword.Pseudo */
.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.codehilite .kt { color: #B00040 } /* Keyword.Type */
.codehilite .m { color: #666666 } /* Literal.Number */
.codehilite .s { color: #BA2121 } /* Literal.String */
.codehilite .na { color: #687822 } /* Name.Attribute */
.codehilite .nb { color: #008000 } /* Name.Builtin */
.codehilite .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.codehilite .no { color: #880000 } /* Name.Constant */
.codehilite .nd { color: #AA22FF } /* Name.Decorator */
.codehilite .ni { color: #717171; font-weight: bold } /* Name.Entity */
.codehilite .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */
.codehilite .nf { color: #0000FF } /* Name.Function */
.codehilite .nl { color: #767600 } /* Name.Label */
.codehilite .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */
.codehilite .nv { color: #19177C } /* Name.Variable */
.codehilite .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.codehilite .w { color: #bbbbbb } /* Text.Whitespace */
.codehilite .mb { color: #666666 } /* Literal.Number.Bin */
.codehilite .mf { color: #666666 } /* Literal.Number.Float */
.codehilite .mh { color: #666666 } /* Literal.Number.Hex */
.codehilite .mi { color: #666666 } /* Literal.Number.Integer */
.codehilite .mo { color: #666666 } /* Literal.Number.Oct */
.codehilite .sa { color: #BA2121 } /* Literal.String.Affix */
.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */
.codehilite .sc { color: #BA2121 } /* Literal.String.Char */
.codehilite .dl { color: #BA2121 } /* Literal.String.Delimiter */
.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */
.codehilite .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */
.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */
.codehilite .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */
.codehilite .sx { color: #008000 } /* Literal.String.Other */
.codehilite .sr { color: #A45A77 } /* Literal.String.Regex */
.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */
.codehilite .ss { color: #19177C } /* Literal.String.Symbol */
.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */
.codehilite .fm { color: #0000FF } /* Name.Function.Magic */
.codehilite .vc { color: #19177C } /* Name.Variable.Class */
.codehilite .vg { color: #19177C } /* Name.Variable.Global */
.codehilite .vi { color: #19177C } /* Name.Variable.Instance */
.codehilite .vm { color: #19177C } /* Name.Variable.Magic */
.codehilite .il { color: #666666 } /* Literal.Number.Integer.Long */

/* Additional styling for specific code elements */
.codehilite pre { margin: 0; padding: 10px; white-space: pre; }
.codehilite code { font-family: 'Consolas', 'Monaco', 'Andale Mono', 'Ubuntu Mono', monospace; }
</style>

            </section>

        </main>
    </div>

    <div id="footer-placeholder"></div>

    <script src="/assets/js/components.js"></script>
<script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true });
    </script>
    <script src="/assets/js/main.js"></script>
    <script src="/assets/js/documentation.js"></script>
    <script>renderDocumentationSidebar('#sidebar-placeholder');</script>
</body>
</html>