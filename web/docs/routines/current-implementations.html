<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Documentation - Universal Automation Wiki</title>
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="stylesheet" href="/assets/css/components.css">
    <link rel="stylesheet" href="/assets/css/category.css"> <!-- For nav cards -->
    <link rel="stylesheet" href="/assets/css/responsive.css">
    <link rel="stylesheet" href="/assets/css/documentation.css"> <!-- Added documentation styles -->
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=IBM+Plex+Sans:wght@400;500;600;700&family=Geologica:wght@400;500;600;700;800;900&display=swap" rel="stylesheet">
    <style>
        /* Placeholder styles to prevent layout shift */
        #header-placeholder { min-height: 70px; }
        #footer-placeholder { min-height: 250px; }
    </style>
</head>
<body>
    <div id="header-placeholder"></div>

    <div class="docs-layout">
        <div id="sidebar-placeholder"></div>

        <main>
            <section class="hero">
                <div class="container">
                    <h1>Current Implementations Assessment</h1>
                    <p class="hero-subtitle">This script analyzes the current state of automation for a given topic. It identifies key process steps, assesses the automation level for each step across different production scales (Low, Medium, High) using a Large Language Model (LLM), and provides explanations for the assessments.</p>
                </div>
            </section>
            <div class="spacer"></div>
            <section class="content-section">
                <div class="spacer"></div>

                <h1>Current Implementations Assessment</h1>
<p>This script analyzes the current state of automation for a given topic. It identifies key process steps, assesses the automation level for each step across different production scales (Low, Medium, High) using a Large Language Model (LLM), and provides explanations for the assessments.</p>
<h2>Purpose</h2>
<p>The primary goal of this script is to generate a structured assessment of how automated the various processes related to a specific topic currently are. It leverages an LLM to analyze the topic and provide ratings and descriptions.</p>
<h2>Usage</h2>
<p>The script is executed from the command line:</p>
<div class="codehilite"><pre><span></span><code>python<span class="w"> </span>current-implementations.py<span class="w"> </span>&lt;input_json&gt;<span class="w"> </span><span class="o">[</span>output_json<span class="o">]</span><span class="w"> </span><span class="o">[</span>-saveInputs<span class="o">]</span><span class="w"> </span><span class="o">[</span>-uuid<span class="o">=</span><span class="s2">&quot;UUID&quot;</span><span class="o">]</span><span class="w"> </span><span class="o">[</span>-flow_uuid<span class="o">=</span><span class="s2">&quot;FLOW-UUID&quot;</span><span class="o">]</span>
</code></pre></div>

<ul>
<li><code>&lt;input_json&gt;</code>: (Required) Path to the input JSON file containing the topic and LLM parameters.</li>
<li><code>[output_json]</code>: (Optional) Path to save the output JSON file. If not provided, a path is generated based on the script name and a UUID.</li>
<li><code>-saveInputs</code>: (Optional) Flag to save the prompts sent to the LLM in the <code>flow/&lt;flowUUID&gt;/inputs/</code> directory.</li>
<li><code>-uuid="UUID"</code>: (Optional) Specify a custom UUID for the output file generation.</li>
<li><code>-flow_uuid="FLOW-UUID"</code>: (Optional) Specify a UUID for the flow, used for saving inputs if <code>-saveInputs</code> is active.</li>
</ul>
<h2>Input Files</h2>
<p>The script requires an input JSON file (<code>&lt;input_json&gt;</code>) with the following structure:</p>
<div class="codehilite"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;topic&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;The topic to be assessed&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gemma3&quot;</span><span class="p">,</span><span class="w"> </span><span class="c1">// Or another LLM model identifier</span>
<span class="w">  </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Optional LLM parameters (e.g., temperature, max_tokens)</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<h2>Key Functions</h2>
<ul>
<li><code>sanitize_json_string(json_str)</code>: Removes invalid control characters from a string to prepare it for JSON parsing.</li>
<li><code>extract_json_from_response(response)</code>: Attempts to extract and parse a valid JSON object from the LLM's response string. It handles direct JSON, JSON within Markdown code fences (<code>json ...</code> or <code>...</code>), and JSON enclosed in curly braces <code>{...}</code>.</li>
<li><code>generate_implementation_assessment(input_data, save_inputs=False)</code>: Orchestrates the assessment generation. It extracts data from the input, constructs the system and user prompts for the LLM, calls <code>chat_with_llm</code>, and uses <code>extract_json_from_response</code> to get the structured data. Optionally saves input prompts.</li>
<li><code>main()</code>: The main execution function. It handles command-line arguments using <code>handle_command_args</code>, loads the input JSON using <code>load_json</code>, calls <code>generate_implementation_assessment</code>, creates output metadata using <code>create_output_metadata</code>, determines the output path using <code>get_output_filepath</code>, and saves the final combined output using <code>save_output</code>.</li>
<li><strong>Utility Functions (from <code>utils.py</code>)</strong>: The script also relies on several functions imported from <code>utils.py</code>, including <code>load_json</code>, <code>save_output</code>, <code>chat_with_llm</code>, <code>create_output_metadata</code>, <code>get_output_filepath</code>, <code>handle_command_args</code>, and <code>saveToFile</code>.</li>
</ul>
<h2>LLM Interaction</h2>
<ol>
<li><strong>Prompt Construction</strong>: A detailed system prompt instructs the LLM to act as an automation analyst, identify process steps for the given topic, assess automation levels ('None', 'Low', 'Medium', 'High') for each step at Low, Medium, and High production scales, provide explanations, and format the output strictly as JSON. The user prompt simply provides the topic.</li>
<li><strong>API Call</strong>: The <code>chat_with_llm</code> function (from <code>utils.py</code>) is used to send the prompts to the specified LLM (<code>model</code> from input).</li>
<li><strong>Expected Response</strong>: The script expects the LLM to return <em>only</em> a valid JSON object containing:<ul>
<li><code>process_steps</code>: An array where each object has <code>step_name</code>, <code>description</code>, <code>automation_levels</code> (object with <code>low_scale</code>, <code>medium_scale</code>, <code>high_scale</code>), and <code>explanation</code>.</li>
<li><code>overall_assessment</code>: A string summarizing the overall automation landscape.</li>
</ul>
</li>
</ol>
<h2>JSON Handling</h2>
<p>Because LLM output can sometimes include extra text or formatting inconsistencies, the script employs robust JSON handling:
*   <code>sanitize_json_string</code>: Cleans the raw response string by removing characters that would invalidate JSON.
*   <code>extract_json_from_response</code>: Tries multiple strategies (direct parsing, code fence extraction, brace extraction) to reliably isolate and parse the JSON payload from the LLM's potentially noisy response. This ensures the script can proceed even if the LLM doesn't perfectly adhere to the "JSON only" instruction.</p>
<h2>Output</h2>
<p>The script generates a JSON output file containing:
*   <code>process_metadata</code>: Information about the script execution, including the process name, start time, and a unique UUID.
*   <code>implementation_assessment</code>: The structured JSON data received and successfully extracted from the LLM, detailing the process steps, automation levels, explanations, and the overall assessment.</p>
<style>
/* Code highlighting styles */
.codehilite .hll { background-color: #ffffcc }
.codehilite { background: #f8f8f8; padding: 0.5em; border-radius: 4px; overflow: auto; }
.codehilite .c { color: #3D7B7B; font-style: italic } /* Comment */
.codehilite .err { border: 1px solid #FF0000 } /* Error */
.codehilite .k { color: #008000; font-weight: bold } /* Keyword */
.codehilite .o { color: #666666 } /* Operator */
.codehilite .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */
.codehilite .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */
.codehilite .cp { color: #9C6500 } /* Comment.Preproc */
.codehilite .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */
.codehilite .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */
.codehilite .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */
.codehilite .gd { color: #A00000 } /* Generic.Deleted */
.codehilite .ge { font-style: italic } /* Generic.Emph */
.codehilite .gr { color: #E40000 } /* Generic.Error */
.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.codehilite .gi { color: #008400 } /* Generic.Inserted */
.codehilite .go { color: #717171 } /* Generic.Output */
.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.codehilite .gs { font-weight: bold } /* Generic.Strong */
.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.codehilite .gt { color: #0044DD } /* Generic.Traceback */
.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.codehilite .kp { color: #008000 } /* Keyword.Pseudo */
.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.codehilite .kt { color: #B00040 } /* Keyword.Type */
.codehilite .m { color: #666666 } /* Literal.Number */
.codehilite .s { color: #BA2121 } /* Literal.String */
.codehilite .na { color: #687822 } /* Name.Attribute */
.codehilite .nb { color: #008000 } /* Name.Builtin */
.codehilite .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.codehilite .no { color: #880000 } /* Name.Constant */
.codehilite .nd { color: #AA22FF } /* Name.Decorator */
.codehilite .ni { color: #717171; font-weight: bold } /* Name.Entity */
.codehilite .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */
.codehilite .nf { color: #0000FF } /* Name.Function */
.codehilite .nl { color: #767600 } /* Name.Label */
.codehilite .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */
.codehilite .nv { color: #19177C } /* Name.Variable */
.codehilite .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.codehilite .w { color: #bbbbbb } /* Text.Whitespace */
.codehilite .mb { color: #666666 } /* Literal.Number.Bin */
.codehilite .mf { color: #666666 } /* Literal.Number.Float */
.codehilite .mh { color: #666666 } /* Literal.Number.Hex */
.codehilite .mi { color: #666666 } /* Literal.Number.Integer */
.codehilite .mo { color: #666666 } /* Literal.Number.Oct */
.codehilite .sa { color: #BA2121 } /* Literal.String.Affix */
.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */
.codehilite .sc { color: #BA2121 } /* Literal.String.Char */
.codehilite .dl { color: #BA2121 } /* Literal.String.Delimiter */
.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */
.codehilite .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */
.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */
.codehilite .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */
.codehilite .sx { color: #008000 } /* Literal.String.Other */
.codehilite .sr { color: #A45A77 } /* Literal.String.Regex */
.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */
.codehilite .ss { color: #19177C } /* Literal.String.Symbol */
.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */
.codehilite .fm { color: #0000FF } /* Name.Function.Magic */
.codehilite .vc { color: #19177C } /* Name.Variable.Class */
.codehilite .vg { color: #19177C } /* Name.Variable.Global */
.codehilite .vi { color: #19177C } /* Name.Variable.Instance */
.codehilite .vm { color: #19177C } /* Name.Variable.Magic */
.codehilite .il { color: #666666 } /* Literal.Number.Integer.Long */

/* Additional styling for specific code elements */
.codehilite pre { margin: 0; padding: 10px; white-space: pre; }
.codehilite code { font-family: 'Consolas', 'Monaco', 'Andale Mono', 'Ubuntu Mono', monospace; }
</style>

            </section>

        </main>
    </div>

    <div id="footer-placeholder"></div>

    <script src="/assets/js/components.js"></script>
<script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true });
    </script>
    <script src="/assets/js/main.js"></script>
    <script src="/assets/js/documentation.js"></script>
    <script>renderDocumentationSidebar('#sidebar-placeholder');</script>
</body>
</html>