<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Documentation - Universal Automation Wiki</title>
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="stylesheet" href="/assets/css/components.css">
    <link rel="stylesheet" href="/assets/css/category.css"> <!-- For nav cards -->
    <link rel="stylesheet" href="/assets/css/responsive.css">
    <link rel="stylesheet" href="/assets/css/documentation.css"> <!-- Added documentation styles -->
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        /* Placeholder styles to prevent layout shift */
        #header-placeholder { min-height: 70px; }
        #footer-placeholder { min-height: 250px; }
    </style>
</head>
<body>
    <div id="header-placeholder"></div>

    <div class="docs-layout">
        <div id="sidebar-placeholder"></div>

        <main>
            <section class="hero">
                <div class="container">
                    <h1>Automation Timeline Generation</h1>
                    <p class="hero-subtitle">This script generates a historical timeline and future predictions for automation technologies related to a specific topic. It utilizes a Large Language Model (LLM) to create the timeline content based on the provided topic.</p>
                </div>
            </section>
            <div class="spacer"></div>
            <section class="content-section">
                <div class="spacer"></div>

                <h1>Automation Timeline Generation</h1>
<p>This script generates a historical timeline and future predictions for automation technologies related to a specific topic. It utilizes a Large Language Model (LLM) to create the timeline content based on the provided topic.</p>
<h2>Purpose</h2>
<p>The primary goal of this script is to produce a structured timeline detailing the evolution and projected future of automation within a given domain. It leverages an LLM to synthesize historical data and make informed predictions.</p>
<h2>Usage</h2>
<p>The script is executed from the command line:</p>
<div class="codehilite"><pre><span></span><code>python<span class="w"> </span>generate_automation_timeline.py<span class="w"> </span>&lt;input_json&gt;<span class="w"> </span><span class="o">[</span>output_json<span class="o">]</span><span class="w"> </span><span class="o">[</span>-saveInputs<span class="o">]</span><span class="w"> </span><span class="o">[</span>-uuid<span class="o">=</span><span class="s2">&quot;UUID&quot;</span><span class="o">]</span><span class="w"> </span><span class="o">[</span>-flow_uuid<span class="o">=</span><span class="s2">&quot;FLOW-UUID&quot;</span><span class="o">]</span>
</code></pre></div>

<p><strong>Arguments:</strong></p>
<ul>
<li><code>&lt;input_json&gt;</code>: (Required) Path to the input JSON file containing the topic and configuration.</li>
<li><code>[output_json]</code>: (Optional) Path where the output JSON timeline should be saved. If not provided, a default path is generated based on the topic and a UUID.</li>
<li><code>-saveInputs</code>: (Optional) Flag to save the system and user prompts sent to the LLM into the <code>flow/&lt;flowUUID&gt;/inputs/</code> directory. Requires <code>-flow_uuid</code> to be set.</li>
<li><code>-uuid="UUID"</code>: (Optional) Custom UUID to use for the output file generation.</li>
<li><code>-flow_uuid="FLOW-UUID"</code>: (Optional) UUID representing the overarching flow this script execution is part of. Used for organizing saved inputs if <code>-saveInputs</code> is active.</li>
</ul>
<h2>Input Files</h2>
<p>The script expects an input JSON file (<code>&lt;input_json&gt;</code>) with the following structure:</p>
<div class="codehilite"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;topic&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Your Automation Topic&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gemma3&quot;</span><span class="p">,</span><span class="w"> </span><span class="c1">// Or another LLM model identifier</span>
<span class="w">  </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Optional LLM parameters (e.g., temperature, top_p)</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;timeline&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="c1">// Optional: If provided, bypasses LLM generation</span>
<span class="w">    </span><span class="nt">&quot;historical&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;1920s&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Description...&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="c1">// ... other decades</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;predictions&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;2030s&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Prediction...&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="c1">// ... other future decades</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<ul>
<li><code>topic</code>: The subject for which the automation timeline should be generated.</li>
<li><code>model</code>: The identifier for the LLM to use (defaults to "gemma3" if not specified).</li>
<li><code>parameters</code>: An object containing any specific parameters to pass to the LLM during generation.</li>
<li><code>timeline</code>: (Optional) If this key exists and contains <code>historical</code> and <code>predictions</code> objects, the script will use this data directly instead of querying the LLM.</li>
</ul>
<h2>Key Functions</h2>
<ul>
<li><strong><code>generate_automation_timeline(input_data, save_inputs=False)</code></strong>:<ul>
<li>Extracts <code>topic</code>, <code>model</code>, and <code>parameters</code> from the input data.</li>
<li>Checks if a <code>timeline</code> already exists in the input; if so, returns it directly.</li>
<li>Constructs system and user prompts for the LLM, requesting a historical timeline (by decade, 1920s-present) and future predictions (by decade until full automation).</li>
<li>Optionally saves the prompts using <code>utils.saveToFile</code> if <code>save_inputs</code> is True.</li>
<li>Calls <code>utils.chat_with_llm</code> to interact with the specified LLM.</li>
<li>Parses the expected JSON response using <code>utils.parse_llm_json_response</code>.</li>
<li>Returns the parsed timeline dictionary or <code>None</code> on error.</li>
</ul>
</li>
<li><strong><code>main()</code></strong>:<ul>
<li>Handles command-line arguments using <code>utils.handle_command_args</code>.</li>
<li>Sets the global <code>flowUUID</code> if provided.</li>
<li>Loads the input JSON using <code>utils.load_json</code>.</li>
<li>Calls <code>generate_automation_timeline</code> to get the timeline data.</li>
<li>Determines the output file path using <code>utils.get_output_filepath</code>.</li>
<li>Creates process metadata (script name, start time, UUID) using <code>utils.create_output_metadata</code>.</li>
<li>Combines metadata and the generated <code>timeline</code> into the final output data structure.</li>
<li>Saves the output data to the determined path using <code>utils.save_output</code>.</li>
</ul>
</li>
<li><strong><code>utils</code> Functions</strong>: The script relies on helper functions imported from <code>utils.py</code> for common tasks like loading/saving JSON (<code>load_json</code>, <code>save_output</code>, <code>saveToFile</code>), interacting with the LLM (<code>chat_with_llm</code>), parsing LLM responses (<code>parse_llm_json_response</code>), creating metadata (<code>create_output_metadata</code>), determining file paths (<code>get_output_filepath</code>), and handling arguments (<code>handle_command_args</code>).</li>
</ul>
<h2>LLM Interaction</h2>
<ol>
<li><strong>Prompt Construction</strong>: A system prompt instructs the LLM to act as an AI specialized in automation timelines. The user prompt specifies the <code>topic</code> and requests:<ul>
<li>Historical developments by decade (1920s-present).</li>
<li>Future predictions by decade until full automation.</li>
<li>Output formatted as a JSON object with <code>historical</code> and <code>predictions</code> keys, where each key holds an object mapping decades (e.g., "1950s", "2040s") to descriptive strings.</li>
</ul>
</li>
<li><strong>API Call</strong>: The <code>chat_with_llm</code> function sends these prompts to the specified LLM (<code>model</code>).</li>
<li><strong>Response Parsing</strong>: The script expects the LLM to return a valid JSON string matching the requested format. <code>parse_llm_json_response</code> attempts to decode this JSON.</li>
<li><strong>Bypass</strong>: If the input JSON already contains a <code>timeline</code> key, the LLM interaction steps are skipped entirely, and the provided timeline is used instead.</li>
</ol>
<h2>Output</h2>
<p>The script generates a JSON file (at <code>[output_json]</code> or a default path) containing:</p>
<div class="codehilite"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;process_metadata&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;script_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Automation Timeline Generation&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;start_time&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;YYYY-MM-DD HH:MM:SS.ffffff&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;end_time&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;YYYY-MM-DD HH:MM:SS.ffffff&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;duration_seconds&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">12.345</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;uuid&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;generated-or-provided-uuid&quot;</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;timeline&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;historical&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;1920s&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;...&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="c1">// ... other decades</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;predictions&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;2030s&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;...&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="c1">// ... other future decades</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<ul>
<li><code>process_metadata</code>: Information about the script execution.</li>
<li><code>timeline</code>: The core output, containing the <code>historical</code> and <code>predictions</code> data, either generated by the LLM or taken directly from the input file.</li>
</ul>
<style>
/* Code highlighting styles */
.codehilite .hll { background-color: #ffffcc }
.codehilite { background: #f8f8f8; padding: 0.5em; border-radius: 4px; overflow: auto; }
.codehilite .c { color: #3D7B7B; font-style: italic } /* Comment */
.codehilite .err { border: 1px solid #FF0000 } /* Error */
.codehilite .k { color: #008000; font-weight: bold } /* Keyword */
.codehilite .o { color: #666666 } /* Operator */
.codehilite .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */
.codehilite .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */
.codehilite .cp { color: #9C6500 } /* Comment.Preproc */
.codehilite .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */
.codehilite .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */
.codehilite .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */
.codehilite .gd { color: #A00000 } /* Generic.Deleted */
.codehilite .ge { font-style: italic } /* Generic.Emph */
.codehilite .gr { color: #E40000 } /* Generic.Error */
.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.codehilite .gi { color: #008400 } /* Generic.Inserted */
.codehilite .go { color: #717171 } /* Generic.Output */
.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.codehilite .gs { font-weight: bold } /* Generic.Strong */
.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.codehilite .gt { color: #0044DD } /* Generic.Traceback */
.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.codehilite .kp { color: #008000 } /* Keyword.Pseudo */
.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.codehilite .kt { color: #B00040 } /* Keyword.Type */
.codehilite .m { color: #666666 } /* Literal.Number */
.codehilite .s { color: #BA2121 } /* Literal.String */
.codehilite .na { color: #687822 } /* Name.Attribute */
.codehilite .nb { color: #008000 } /* Name.Builtin */
.codehilite .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.codehilite .no { color: #880000 } /* Name.Constant */
.codehilite .nd { color: #AA22FF } /* Name.Decorator */
.codehilite .ni { color: #717171; font-weight: bold } /* Name.Entity */
.codehilite .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */
.codehilite .nf { color: #0000FF } /* Name.Function */
.codehilite .nl { color: #767600 } /* Name.Label */
.codehilite .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */
.codehilite .nv { color: #19177C } /* Name.Variable */
.codehilite .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.codehilite .w { color: #bbbbbb } /* Text.Whitespace */
.codehilite .mb { color: #666666 } /* Literal.Number.Bin */
.codehilite .mf { color: #666666 } /* Literal.Number.Float */
.codehilite .mh { color: #666666 } /* Literal.Number.Hex */
.codehilite .mi { color: #666666 } /* Literal.Number.Integer */
.codehilite .mo { color: #666666 } /* Literal.Number.Oct */
.codehilite .sa { color: #BA2121 } /* Literal.String.Affix */
.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */
.codehilite .sc { color: #BA2121 } /* Literal.String.Char */
.codehilite .dl { color: #BA2121 } /* Literal.String.Delimiter */
.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */
.codehilite .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */
.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */
.codehilite .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */
.codehilite .sx { color: #008000 } /* Literal.String.Other */
.codehilite .sr { color: #A45A77 } /* Literal.String.Regex */
.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */
.codehilite .ss { color: #19177C } /* Literal.String.Symbol */
.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */
.codehilite .fm { color: #0000FF } /* Name.Function.Magic */
.codehilite .vc { color: #19177C } /* Name.Variable.Class */
.codehilite .vg { color: #19177C } /* Name.Variable.Global */
.codehilite .vi { color: #19177C } /* Name.Variable.Instance */
.codehilite .vm { color: #19177C } /* Name.Variable.Magic */
.codehilite .il { color: #666666 } /* Literal.Number.Integer.Long */

/* Additional styling for specific code elements */
.codehilite pre { margin: 0; padding: 10px; white-space: pre; }
.codehilite code { font-family: 'Consolas', 'Monaco', 'Andale Mono', 'Ubuntu Mono', monospace; }
</style>

            </section>

        </main>
    </div>

    <div id="footer-placeholder"></div>

    <script src="/assets/js/components.js"></script>
<script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true });
    </script>
    <script src="/assets/js/main.js"></script>
    <script src="/assets/js/documentation.js"></script>
    <script>renderDocumentationSidebar('#sidebar-placeholder');</script>
</body>
</html>